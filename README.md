# Flume

A message streaming system built from scratch in Go. Not a Kafka wrapper â€” the core primitives implemented manually to understand log-structured storage, consumer coordination, and backpressure.

## Status

ğŸš§ **In Development**

| Phase | Description | Status |
|-------|-------------|--------|
| 1 | Single-topic broker | Not started |
| 2 | Multi-topic + partitions | Not started |
| 3 | Consumer groups | Not started |
| 4 | Backpressure | Not started |
| 5 | Benchmarks | Not started |

## What This Is

A learning project that implements:

- **Log-structured storage** â€” append-only logs with offset-based reads
- **Partitioned topics** â€” parallelism with ordering guarantees per partition
- **Consumer groups** â€” coordinated consumption with rebalancing
- **Backpressure** â€” bounded buffers to handle slow consumers

## What This Is Not

- Not distributed (single broker, no replication)
- Not production-ready
- Not a Kafka clone â€” intentionally limited scope

## Architecture

```
Producers â†’ Broker â†’ Consumers
              â”‚
         â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
         â”‚  Topics â”‚
         â”‚ â”Œâ”€â”€â”€â”€â”€â” â”‚
         â”‚ â”‚ P0  â”‚ â”‚  â† Partitions (separate log files)
         â”‚ â”‚ P1  â”‚ â”‚
         â”‚ â”‚ P2  â”‚ â”‚
         â”‚ â””â”€â”€â”€â”€â”€â”˜ â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

<!-- TODO: expand after Phase 1 complete -->

## Usage

```bash
# TODO: add commands after implementation
```

## Benchmarks

<!-- TODO: fill after Phase 5 -->

| Metric | Value |
|--------|-------|
| Throughput | TBD |
| p99 Latency | TBD |
| Recovery time (1M msgs) | TBD |

## Design Decisions

<!-- Document trade-offs as you build -->

## What I Learned

<!-- Add insights after each phase -->
